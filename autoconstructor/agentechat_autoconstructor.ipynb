{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoBuild\n",
    "AutoGen ofrece agentes conversables impulsados por LLM, herramienta o humano, que se pueden utilizar para realizar tareas colectivamente a través de chat automatizado. Este marco permite el uso de herramientas y la participación humana a través de conversación multiagente.\n",
    "Por favor, encuentre la documentación sobre esta característica [aquí](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "En este cuaderno, presentamos una nueva clase, `AgentBuilder`, para ayudar al usuario a construir un proceso de resolución de tareas automático impulsado por un sistema multiagente. Específicamente, en `build()`, solicitamos a un LLM que cree varios agentes participantes e inicialice un chat grupal, y especificamos si esta tarea necesita programación para resolverse. AgentBuilder también soporta LLMs de código abierto por [vLLM](https://docs.vllm.ai/en/latest/index.html) y [Fastchat](https://github.com/lm-sys/FastChat). Consulte la lista de modelos soportados [aquí](https://docs.vllm.ai/en/latest/models/supported_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisito\n",
    "\n",
    "AutoBuild necesita la última versión de AutoGen.\n",
    "Puede instalar AutoGen con el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pyautogen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: preparar la configuración\n",
    "Prepare un `config_path` para el agente asistente para limitar la elección del LLM que desea utilizar en esta tarea. Esta configuración puede ser una ruta de archivo json o un nombre de variable de entorno. También se requiere un `default_llm_config` para inicializar la configuración específica de los LLMs como semilla, temperatura, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'OAI_CONFIG_LIST.json'  # modify path\n",
    "default_llm_config = {\n",
    "    'temperature': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: crear un AgentBuilder\n",
    "Cree un `AgentBuilder` con el `config_path` especificado. Por defecto, AgentBuilder utilizará GPT-4 para completar todo el proceso, también puede cambiar el `builder_model` a otro modelo de OpenAI si lo desea. También puede especificar un LLM de OpenAI o de código abierto como columna vertebral del agente, vea el blog para más detalles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.contrib.agent_builder import AgentBuilder\n",
    "\n",
    "builder = AgentBuilder(config_path=config_path, builder_model='gpt-4-1106-preview', agent_model='gpt-4-1106-preview')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: especificar una tarea de construcción\n",
    "\n",
    "Especifique una tarea de construcción con una descripción general. La tarea de construcción ayudará al gestor de construcción (un LLM) a decidir qué agentes se deben construir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_task = \"Corregir, mejorar y traducir textos del español al inglés y viceversa. Cuando el texto este terminado salvar un markdown con toda la informacion y presentado de una forma correcta y legible.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: construir agentes de chat grupal\n",
    "Use `build()` para permitir que el gestor de construcción (el `builder_model` especificado) complete la generación de agentes de chat grupal. Si cree que la codificación es necesaria en su tarea, puede usar `coding=True` para agregar un proxy de usuario (un intérprete de código automático) a la lista de agentes, como:\n",
    "```python\n",
    "builder.build(building_task, default_llm_config, coding=True)\n",
    "```\n",
    "Si no se especifica `coding`, AgentBuilder determinará por sí mismo si se debe agregar o no el proxy de usuario de acuerdo con la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_list, agent_configs = builder.build(building_task, default_llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: ejecutar la tarea\n",
    "Permita que los agentes generados en `build()` completen la tarea de manera colaborativa en un chat grupal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "def start_task(execution_task: str, agent_list: list, llm_config: dict):\n",
    "    config_list = autogen.config_list_from_json(config_path, filter_dict={\"model\": [\"gpt-4-1106-preview\"]})\n",
    "    \n",
    "    group_chat = autogen.GroupChat(agents=agent_list, messages=[], max_round=12)\n",
    "    manager = autogen.GroupChatManager(\n",
    "        groupchat=group_chat, llm_config={\"config_list\": config_list, **llm_config}\n",
    "    )\n",
    "    agent_list[0].initiate_chat(manager, message=execution_task)\n",
    "\n",
    "start_task(\n",
    "    # execution_task es la tarea que el equipo de agentes debe realizar\n",
    "    execution_task=\"Crea un texto dando la vienvenida a los nuevos estudiantes de mi academia de gimnasia artistica en español y en ingles.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar y cargar configuraciones\n",
    "\n",
    "Puedes guardar toda la información necesaria de los agentes de chat grupal construidos. Aquí hay un caso para esos agentes generados en la tarea anterior:\n",
    "\n",
    "Esta información se guardará en formato JSON. Puedes proporcionar un nombre de archivo específico, de lo contrario, AgentBuilder guardará la configuración en la ruta actual con un nombre de archivo generado 'save_config_TASK_MD5.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_path = builder.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de eso, puedes cargar la configuración guardada y saltarte el proceso de construcción. AgentBuilder creará agentes con esa información sin solicitar al gestor de construcción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_builder = AgentBuilder(config_path=config_path)\n",
    "agent_list, agent_configs = new_builder.load(saved_path)  # load previous agent configs\n",
    "start_task(\n",
    "    execution_task=\"Corregir, mejorar y traducir textos del español al inglés y viceversa. Cuando el texto este terminado salvar un markdown con toda la informacion y presentado de una forma correcta y legible.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")\n",
    "new_builder.clear_all_agents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Opcional): limpiar todos los agentes y prepararse para la próxima tarea\n",
    "Puedes limpiar todos los agentes generados en esta tarea con el siguiente código si tu tarea se ha completado o si la próxima tarea es muy diferente de la tarea actual. Si la columna vertebral del agente es un LLM de código abierto, este proceso también cerrará el servidor de punto final. Si es necesario, puedes usar `recycle_endpoint=False` para mantener el servidor de punto final de los LLMs de código abierto anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.clear_all_agents(recycle_endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizar el Asistente de OpenAI\n",
    "\n",
    "[La API de Asistentes](https://platform.openai.com/docs/assistants/overview) te permite construir asistentes de IA dentro de tus propias aplicaciones. Un Asistente tiene instrucciones y puede aprovechar modelos, herramientas y conocimientos para responder a las consultas de los usuarios.\n",
    "AutoBuild también soporta la API de asistentes añadiendo `use_oai_assistant=True` a `build()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_builder = AgentBuilder(config_path=config_path)\n",
    "agent_list, agent_configs = new_builder.build(building_task, default_llm_config, use_oai_assistant=True)  # Transfer to OpenAI assistant API.\n",
    "start_task(\n",
    "    execution_task=\"Find a recent paper about XAI on arxiv and find its potential applications in medical.\",\n",
    "    agent_list=agent_list,\n",
    "    llm_config=default_llm_config\n",
    ")\n",
    "new_builder.clear_all_agents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
